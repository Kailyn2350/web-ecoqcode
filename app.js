// python -m http.server 8000
// ngrok http 8000

const modelPath = "model/model_simplified.onnx";
let session;

const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

async function initCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
  video.srcObject = stream;
  return new Promise(resolve => video.onloadedmetadata = resolve);
}

async function loadModel() {
  session = await ort.InferenceSession.create(modelPath);
  console.log("ONNX model loaded");
}

function preprocessFrame() {
  const size = 640; // ëª¨ë¸ ì…ë ¥ ì‚¬ì´ì¦ˆ
  const cropSize = 320; // ìë¥¼ ì¤‘ì•™ ì˜ì—­ ì‚¬ì´ì¦ˆ (px)

  const tempCanvas = document.createElement("canvas");
  tempCanvas.width = size;
  tempCanvas.height = size;
  const tempCtx = tempCanvas.getContext("2d");

  // âš ï¸ ì˜ìƒ í¬ê¸°ê°€ ì•„ì§ ì„¤ì • ì•ˆ ëì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ë³´ì •
  const vw = video.videoWidth || 640;
  const vh = video.videoHeight || 480;

  const sx = (vw - cropSize) / 2;
  const sy = (vh - cropSize) / 2;

  // ğŸ“Œ ì¤‘ì•™ ì˜ì—­ ìë¥´ê¸° â†’ (sx, sy, cropSize, cropSize)ë¥¼ (0,0,size,size)ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
  tempCtx.drawImage(video, sx, sy, cropSize, cropSize, 0, 0, size, size);

  const imgData = tempCtx.getImageData(0, 0, size, size).data;
  const float32 = new Float32Array(1 * 3 * size * size);
  for (let i = 0; i < size * size; i++) {
    float32[i] = imgData[i * 4] / 255;
    float32[i + size * size] = imgData[i * 4 + 1] / 255;
    float32[i + 2 * size * size] = imgData[i * 4 + 2] / 255;
  }

  return new ort.Tensor("float32", float32, [1, 3, size, size]);
}


function drawBoxes(detections) {
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  drawMask();  // âœ… ì¶”ê°€

  const highConfDetections = detections.filter(det => det.score >= 0.5);
  const count = highConfDetections.length;

  document.getElementById("banner").style.display = count >= 3 ? "block" : "none";
}

function drawMask() {
  const w = canvas.width;
  const h = canvas.height;

  // ë§ˆìŠ¤í¬ í¬ê¸°: í™”ë©´ ê°€ìš´ë° ì •ì‚¬ê°í˜•
  const boxSize = Math.min(w, h) * 0.6;
  const left = (w - boxSize) / 2;
  const top = (h - boxSize) / 2;

  ctx.save();
  ctx.fillStyle = "rgba(0, 0, 0, 0.6)";
  ctx.beginPath();
  ctx.rect(0, 0, w, h); // ì „ì²´ ì–´ë‘¡ê²Œ
  ctx.rect(left, top, boxSize, boxSize); // ê°€ìš´ë° ëš«ìŒ
  ctx.fill("evenodd"); // ëš«ê¸° ëª¨ë“œ
  ctx.restore();
}


function postprocess(outputTensor) {
  const raw = outputTensor.data;
  const numDet = raw.length / 6; // í˜¹ì€ 85ë¡œ ë‚˜ëˆ„ê±°ë‚˜, êµ¬ì¡°ë¥¼ ë¡œê·¸ë¡œ í™•ì¸
  const detections = [];

  for (let i = 0; i < raw.length; i += 6) {
    const cx = raw[i];
    const cy = raw[i + 1];
    const w = raw[i + 2];
    const h = raw[i + 3];
    const obj = raw[i + 4];
    const cls = raw[i + 5];  // â—ï¸ì´ê²Œ í™•ë¥ ì¸ì§€ indexì¸ì§€ í™•ì¸ í•„ìš”

    const score = obj * cls;

    // ë„ˆë¬´ ë§ì€ ì˜¤íƒ ë°©ì§€
    if (obj > 0.5 && cls > 0.8 && w * h > 0.001 && w * h < 0.5) {
      detections.push({
        label: "ECOQCODE",
        score,
        box: [cx - w / 2, cy - h / 2, w, h]
      });
    }
  }

  console.log("ğŸ“¦ Detections:", detections);
  return detections;
}


async function detectLoop() {
  if (!session) return;
  const tensor = preprocessFrame();
  const outputMap = await session.run({ images: tensor });

  // ğŸ”¥ ì—¬ê¸°ê°€ ì¤‘ìš”
  const outputName = session.outputNames[0];
  const outputTensor = outputMap[outputName];

  const results = postprocess(outputTensor);
  drawBoxes(results);
  requestAnimationFrame(detectLoop);
}


async function main() {
  await initCamera();
  await loadModel();

  // ì˜ìƒ ì •ë³´ í™•ë³´ë¥¼ ìœ„í•œ ëŒ€ê¸° (1í”„ë ˆì„ ë’¤ì—ì•¼ width/height ì ‘ê·¼ ê°€ëŠ¥)
  await new Promise(resolve => setTimeout(resolve, 500));

  // ğŸ“Œ ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì •
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;

  detectLoop();
}


main();
